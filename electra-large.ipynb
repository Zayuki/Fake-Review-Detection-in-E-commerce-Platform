{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6488923,"sourceType":"datasetVersion","datasetId":3749709},{"sourceId":6506219,"sourceType":"datasetVersion","datasetId":3761537}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"*This is ELECTRA*","metadata":{"_uuid":"119a92a1-6d93-4953-b1be-75cfaf076af2","_cell_guid":"15ad5e84-8656-4da8-9989-67a31950d0eb","id":"Zcys-EiEHqwS","trusted":true}},{"cell_type":"code","source":"!pip install transformers --upgrade\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import ElectraForSequenceClassification, ElectraTokenizer, ElectraTokenizerFast\nfrom sklearn.model_selection import train_test_split\nfrom torch import cuda\nimport time\nfrom torch.nn import DataParallel","metadata":{"_uuid":"8624e580-5f2a-4bc8-b4e4-55c842167e9c","_cell_guid":"7490d45d-ed8b-4e0d-a8b2-5fa06a9fb2e8","collapsed":false,"id":"XyFzcUVpR3bO","outputId":"c717bf56-2d56-4c71-ca52-5946159f1b68","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:15.423965Z","iopub.execute_input":"2023-12-16T16:54:15.424401Z","iopub.status.idle":"2023-12-16T16:54:31.244221Z","shell.execute_reply.started":"2023-12-16T16:54:15.424363Z","shell.execute_reply":"2023-12-16T16:54:31.243062Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"_uuid":"067e1992-bfc7-45f9-9734-206ca1bb8f13","_cell_guid":"ee44e2f6-a9c1-4617-90e9-9d1d52833b07","collapsed":false,"id":"ibiw-qSnHqwW","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.250061Z","iopub.execute_input":"2023-12-16T16:54:31.250514Z","iopub.status.idle":"2023-12-16T16:54:31.336604Z","shell.execute_reply.started":"2023-12-16T16:54:31.250479Z","shell.execute_reply":"2023-12-16T16:54:31.335530Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"encoded_label_dict = {\"CG\" : 0, \"OR\" : 1}\ndef encode_label(x):\n    return encoded_label_dict.get(x,-1)","metadata":{"_uuid":"4156df87-ed64-4048-b51a-9d7d88253ae7","_cell_guid":"183a4e72-d4f3-46ca-8a79-1a52166a1161","collapsed":false,"id":"m5oB534AHqwW","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.338253Z","iopub.execute_input":"2023-12-16T16:54:31.338660Z","iopub.status.idle":"2023-12-16T16:54:31.364887Z","shell.execute_reply.started":"2023-12-16T16:54:31.338626Z","shell.execute_reply":"2023-12-16T16:54:31.363924Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/fake-reviews-dataset/fake reviews dataset.csv\")","metadata":{"_uuid":"e095dd06-4c05-4a0e-8a6a-aced47134a9a","_cell_guid":"7317a4b1-4adb-4c15-b9ce-be2ca4bf240c","collapsed":false,"id":"L7pzb-l1HqwX","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.368520Z","iopub.execute_input":"2023-12-16T16:54:31.369083Z","iopub.status.idle":"2023-12-16T16:54:31.549005Z","shell.execute_reply.started":"2023-12-16T16:54:31.369054Z","shell.execute_reply":"2023-12-16T16:54:31.547988Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df[\"target\"] = df[\"label\"].apply(lambda x: encode_label(x))","metadata":{"_uuid":"310e6dba-1ba8-414d-b097-6e8bda2b44cb","_cell_guid":"99085afd-d06a-4722-a4fb-655c1894883c","collapsed":false,"id":"8heLsh83HqwX","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.551066Z","iopub.execute_input":"2023-12-16T16:54:31.551389Z","iopub.status.idle":"2023-12-16T16:54:31.588981Z","shell.execute_reply.started":"2023-12-16T16:54:31.551361Z","shell.execute_reply":"2023-12-16T16:54:31.588182Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model_name = \"google/electra-large-discriminator\"\nMAX_LEN = 512 #maximum sequence length\nTRAIN_BATCH_SIZE = 8\nVALID_BATCH_SIZE = 8\nEPOCHS = 2\nLEARNING_RATE = 1e-05","metadata":{"_uuid":"47f1bca7-c9c8-4768-a170-d1deedd28309","_cell_guid":"3570355a-71f0-43a7-af25-a0e96f0ca9ea","collapsed":false,"id":"w6ott4b4ZAg0","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.590247Z","iopub.execute_input":"2023-12-16T16:54:31.590854Z","iopub.status.idle":"2023-12-16T16:54:31.597892Z","shell.execute_reply.started":"2023-12-16T16:54:31.590818Z","shell.execute_reply":"2023-12-16T16:54:31.597065Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Initialize ElectraTokenizer\n#tokenizer = ElectraTokenizer.from_pretrained(model_name)\ntokenizer = ElectraTokenizerFast.from_pretrained(model_name, bos_token='<s>', eos_token='</s>')","metadata":{"_uuid":"97bbe499-4c47-430c-88ac-bf9194758664","_cell_guid":"158945f4-3596-4a82-ab9a-035699c875f0","collapsed":false,"id":"iEYMSt4dHqwX","scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.599003Z","iopub.execute_input":"2023-12-16T16:54:31.599284Z","iopub.status.idle":"2023-12-16T16:54:31.794272Z","shell.execute_reply.started":"2023-12-16T16:54:31.599261Z","shell.execute_reply":"2023-12-16T16:54:31.793257Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Triage(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __getitem__(self, index):\n        text = str(self.data.text_[index])\n        text = \" \".join(text.split())\n        inputs = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n        }\n\n    def __len__(self):\n        return self.len","metadata":{"_uuid":"bead355e-61f5-4a0e-974f-adf217749237","_cell_guid":"e124681a-4e6c-43e0-a84a-1e19cf2d28ba","collapsed":false,"id":"2mqS_gVYZokN","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.795670Z","iopub.execute_input":"2023-12-16T16:54:31.796311Z","iopub.status.idle":"2023-12-16T16:54:31.804781Z","shell.execute_reply.started":"2023-12-16T16:54:31.796274Z","shell.execute_reply":"2023-12-16T16:54:31.803851Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Creating the dataset and dataloader\ntrain_dataset, valid_dataset = train_test_split(df, test_size=0.2, shuffle=True, stratify=None, random_state=2021)\ntrain_dataset = train_dataset.reset_index(drop=True)\nvalid_dataset = valid_dataset.reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(df.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"VALID Dataset: {}\".format(valid_dataset.shape))\n\ntraining_set = Triage(train_dataset, tokenizer, MAX_LEN)\ntesting_set = Triage(valid_dataset, tokenizer, MAX_LEN)","metadata":{"_uuid":"1026d88e-6cb3-4998-8b43-c768c153b0d0","_cell_guid":"5422da93-045a-439d-a38f-b0dce9bfdd68","collapsed":false,"id":"rn6qFvnOHqwY","outputId":"d1b4f5d9-1c2c-441d-fe3f-c276068cec7d","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.805936Z","iopub.execute_input":"2023-12-16T16:54:31.806267Z","iopub.status.idle":"2023-12-16T16:54:31.826380Z","shell.execute_reply.started":"2023-12-16T16:54:31.806233Z","shell.execute_reply":"2023-12-16T16:54:31.825463Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"FULL Dataset: (40432, 5)\nTRAIN Dataset: (32345, 5)\nVALID Dataset: (8087, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\nvalid_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **valid_params)","metadata":{"_uuid":"f367e270-659d-4c83-b0ae-412b8a220462","_cell_guid":"8ed787e4-e990-45b1-992c-afbd911a4a28","collapsed":false,"id":"r5pGVEB8HqwZ","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.827439Z","iopub.execute_input":"2023-12-16T16:54:31.827726Z","iopub.status.idle":"2023-12-16T16:54:31.833275Z","shell.execute_reply.started":"2023-12-16T16:54:31.827700Z","shell.execute_reply":"2023-12-16T16:54:31.832099Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = ElectraForSequenceClassification.from_pretrained(model_name)\nmodel = DataParallel(model)\nmodel.to(device)","metadata":{"_uuid":"6faf14a4-a3a0-4a01-8ba1-108e14b56819","_cell_guid":"33b39727-207f-43a6-97e8-6c9d64c935ea","collapsed":false,"id":"s90EAQBdHqwZ","outputId":"f164393f-420c-409b-a06d-4c5a728799ea","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:31.834546Z","iopub.execute_input":"2023-12-16T16:54:31.834794Z","iopub.status.idle":"2023-12-16T16:54:36.394088Z","shell.execute_reply.started":"2023-12-16T16:54:31.834772Z","shell.execute_reply":"2023-12-16T16:54:36.393230Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): ElectraForSequenceClassification(\n    (electra): ElectraModel(\n      (embeddings): ElectraEmbeddings(\n        (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n        (position_embeddings): Embedding(512, 1024)\n        (token_type_embeddings): Embedding(2, 1024)\n        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): ElectraEncoder(\n        (layer): ModuleList(\n          (0-23): 24 x ElectraLayer(\n            (attention): ElectraAttention(\n              (self): ElectraSelfAttention(\n                (query): Linear(in_features=1024, out_features=1024, bias=True)\n                (key): Linear(in_features=1024, out_features=1024, bias=True)\n                (value): Linear(in_features=1024, out_features=1024, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): ElectraSelfOutput(\n                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): ElectraIntermediate(\n              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): ElectraOutput(\n              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (classifier): ElectraClassificationHead(\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Creating the optimizer\noptimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)","metadata":{"_uuid":"0b1892d4-4704-448d-a7e0-23e672be970c","_cell_guid":"204c8326-94ed-44ba-8f60-6b2cf0d37ee1","collapsed":false,"id":"uGEUeQFYHqwZ","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:36.395391Z","iopub.execute_input":"2023-12-16T16:54:36.396080Z","iopub.status.idle":"2023-12-16T16:54:36.402957Z","shell.execute_reply.started":"2023-12-16T16:54:36.396045Z","shell.execute_reply":"2023-12-16T16:54:36.402018Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Function to calcuate the accuracy of the model\ndef calcuate_accu(big_idx, targets):\n    n_correct = (big_idx==targets).sum().item()\n    return n_correct","metadata":{"_uuid":"ef477ae4-ec0f-4d9d-af51-cded4c75bff4","_cell_guid":"6a321f60-32ce-42d5-8e82-0615770fd0db","collapsed":false,"id":"tt-i7CWBHqwZ","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:36.407385Z","iopub.execute_input":"2023-12-16T16:54:36.407704Z","iopub.status.idle":"2023-12-16T16:54:36.413573Z","shell.execute_reply.started":"2023-12-16T16:54:36.407682Z","shell.execute_reply":"2023-12-16T16:54:36.412762Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    model.train()\n    tr_loss = 0\n    n_correct = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    start_time = time.time()\n\n    for step, data in enumerate(training_loader, 0):\n        ids = data['ids'].to(device, dtype=torch.long)\n        mask = data['mask'].to(device, dtype=torch.long)\n        targets = data['targets'].to(device, dtype=torch.long)\n\n        optimizer.zero_grad()\n        outputs = model(ids, attention_mask=mask, labels=targets)\n        loss = outputs.loss\n\n        if loss.dim() > 0:\n            loss = loss.mean()\n\n        tr_loss += loss.item()\n        logits = outputs.logits\n        big_val, big_idx = torch.max(logits, dim=1)\n        n_correct += calcuate_accu(big_idx, targets)\n\n        nb_tr_steps += 1\n        nb_tr_examples += targets.size(0)\n\n        loss.backward()\n        optimizer.step()\n\n        # Print metrics every 100 steps\n        if (step + 1) % 100 == 0:\n            interim_loss = tr_loss / nb_tr_steps\n            interim_acc = (n_correct * 100) / nb_tr_examples\n            print(f\"Epoch {epoch}, Step {step+1} - Training Loss: {interim_loss}, Training Accuracy: {interim_acc}%\")\n\n    elapsed_time = time.time() - start_time\n    epoch_loss = tr_loss / len(training_loader)\n    epoch_acc = (n_correct * 100) / nb_tr_examples\n    print(f\"Epoch {epoch} Completed - Average Loss: {epoch_loss}, Average Accuracy: {epoch_acc}%, Time: {elapsed_time:.2f} seconds\")\n\n    return epoch_loss, epoch_acc","metadata":{"_uuid":"ddf2018b-205b-4840-8e8d-535502c7ab77","_cell_guid":"c6b8b3fa-e540-4228-8db8-8b2fded08737","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:36.414495Z","iopub.execute_input":"2023-12-16T16:54:36.414741Z","iopub.status.idle":"2023-12-16T16:54:36.426234Z","shell.execute_reply.started":"2023-12-16T16:54:36.414718Z","shell.execute_reply":"2023-12-16T16:54:36.425386Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    model.eval()\n    n_correct = 0\n    n_wrong = 0\n    total = 0\n    tr_loss = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    with torch.no_grad():\n        for _, data in enumerate(testing_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.long)\n            outputs = model(ids, attention_mask=mask, labels=targets)\n            loss = outputs.loss\n            logits = outputs.logits\n            tr_loss += loss\n            big_val, big_idx = torch.max(logits, dim=1)\n            n_correct += calcuate_accu(big_idx, targets)\n\n            nb_tr_steps += 1\n            nb_tr_examples+=targets.size(0)\n\n            if _!=0 and _%100==0:\n                loss_step = tr_loss/nb_tr_steps\n                accu_step = (n_correct*100)/nb_tr_examples\n                print(f\"Validation Loss per 100 steps: {loss_step}\")\n                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Validation Loss Epoch: {epoch_loss}\")\n    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n\n    return epoch_accu","metadata":{"_uuid":"78a95142-edfa-4fd6-aee1-19edee58750a","_cell_guid":"6b7deae5-3146-444a-aace-b7319de75774","collapsed":false,"id":"PL0IJ9BJHqwZ","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:36.427356Z","iopub.execute_input":"2023-12-16T16:54:36.427696Z","iopub.status.idle":"2023-12-16T16:54:36.439542Z","shell.execute_reply.started":"2023-12-16T16:54:36.427663Z","shell.execute_reply":"2023-12-16T16:54:36.438806Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tokenizer.pad_token_id","metadata":{"_uuid":"3d203bbf-9450-4611-9b33-2a628d2824ea","_cell_guid":"b05f5669-4994-40ec-a0b9-030a743452a7","collapsed":false,"id":"XTurIxk0HqwZ","outputId":"39412f6e-f326-4013-dabb-3cd3085a3a5d","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:36.440565Z","iopub.execute_input":"2023-12-16T16:54:36.440887Z","iopub.status.idle":"2023-12-16T16:54:36.454425Z","shell.execute_reply.started":"2023-12-16T16:54:36.440854Z","shell.execute_reply":"2023-12-16T16:54:36.453579Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    train(epoch)\n    acc = valid(model, testing_loader)\n    print(\"Accuracy on validation data for epoch %d = %0.2f%%\" % (epoch, acc))","metadata":{"_uuid":"7aaa239a-c993-4854-bff7-4a06a66210ab","_cell_guid":"32641340-030b-4c9d-b194-b35766851132","collapsed":false,"id":"BGJHgALVdELJ","outputId":"d072a756-a261-4aac-ab49-3e2ff8bea95d","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T16:54:36.455611Z","iopub.execute_input":"2023-12-16T16:54:36.455940Z","iopub.status.idle":"2023-12-16T20:45:05.165212Z","shell.execute_reply.started":"2023-12-16T16:54:36.455907Z","shell.execute_reply":"2023-12-16T20:45:05.164240Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0, Step 100 - Training Loss: 0.44774562917649746, Training Accuracy: 80.75%\nEpoch 0, Step 200 - Training Loss: 0.3196585702523589, Training Accuracy: 87.125%\nEpoch 0, Step 300 - Training Loss: 0.2624456948041916, Training Accuracy: 89.625%\nEpoch 0, Step 400 - Training Loss: 0.25559876635205003, Training Accuracy: 90.1875%\nEpoch 0, Step 500 - Training Loss: 0.23369437461718917, Training Accuracy: 91.225%\nEpoch 0, Step 600 - Training Loss: 0.21830402671049037, Training Accuracy: 91.6875%\nEpoch 0, Step 700 - Training Loss: 0.20311370268597134, Training Accuracy: 92.28571428571429%\nEpoch 0, Step 800 - Training Loss: 0.1907684998138575, Training Accuracy: 92.828125%\nEpoch 0, Step 900 - Training Loss: 0.18319129448073607, Training Accuracy: 93.05555555555556%\nEpoch 0, Step 1000 - Training Loss: 0.17579259468242525, Training Accuracy: 93.3625%\nEpoch 0, Step 1100 - Training Loss: 0.16871040590573103, Training Accuracy: 93.67045454545455%\nEpoch 0, Step 1200 - Training Loss: 0.16450871674149917, Training Accuracy: 93.84375%\nEpoch 0, Step 1300 - Training Loss: 0.15884514052993975, Training Accuracy: 94.03846153846153%\nEpoch 0, Step 1400 - Training Loss: 0.15456610956428837, Training Accuracy: 94.25%\nEpoch 0, Step 1500 - Training Loss: 0.14946537642553448, Training Accuracy: 94.44166666666666%\nEpoch 0, Step 1600 - Training Loss: 0.14578063107823255, Training Accuracy: 94.5625%\nEpoch 0, Step 1700 - Training Loss: 0.143238856134361, Training Accuracy: 94.6029411764706%\nEpoch 0, Step 1800 - Training Loss: 0.1392101468112863, Training Accuracy: 94.74305555555556%\nEpoch 0, Step 1900 - Training Loss: 0.13624794806151552, Training Accuracy: 94.84210526315789%\nEpoch 0, Step 2000 - Training Loss: 0.13273087678838055, Training Accuracy: 94.9875%\nEpoch 0, Step 2100 - Training Loss: 0.12950433628533833, Training Accuracy: 95.125%\nEpoch 0, Step 2200 - Training Loss: 0.12721837185630153, Training Accuracy: 95.23295454545455%\nEpoch 0, Step 2300 - Training Loss: 0.12578533489510174, Training Accuracy: 95.28260869565217%\nEpoch 0, Step 2400 - Training Loss: 0.12343851563089023, Training Accuracy: 95.359375%\nEpoch 0, Step 2500 - Training Loss: 0.12034817364886403, Training Accuracy: 95.48%\nEpoch 0, Step 2600 - Training Loss: 0.11883208754248559, Training Accuracy: 95.54326923076923%\nEpoch 0, Step 2700 - Training Loss: 0.1175227874718365, Training Accuracy: 95.60185185185185%\nEpoch 0, Step 2800 - Training Loss: 0.11558966475630379, Training Accuracy: 95.65178571428571%\nEpoch 0, Step 2900 - Training Loss: 0.11436018542667593, Training Accuracy: 95.70689655172414%\nEpoch 0, Step 3000 - Training Loss: 0.111961477640667, Training Accuracy: 95.78333333333333%\nEpoch 0, Step 3100 - Training Loss: 0.11091363630959794, Training Accuracy: 95.8225806451613%\nEpoch 0, Step 3200 - Training Loss: 0.10903512123670225, Training Accuracy: 95.90625%\nEpoch 0, Step 3300 - Training Loss: 0.10811433482699971, Training Accuracy: 95.93560606060606%\nEpoch 0, Step 3400 - Training Loss: 0.10716971387288889, Training Accuracy: 95.97426470588235%\nEpoch 0, Step 3500 - Training Loss: 0.10556714620554287, Training Accuracy: 96.03214285714286%\nEpoch 0, Step 3600 - Training Loss: 0.10452369420698637, Training Accuracy: 96.0625%\nEpoch 0, Step 3700 - Training Loss: 0.10301548729881933, Training Accuracy: 96.12162162162163%\nEpoch 0, Step 3800 - Training Loss: 0.10306950381828325, Training Accuracy: 96.13486842105263%\nEpoch 0, Step 3900 - Training Loss: 0.10273466444151917, Training Accuracy: 96.1474358974359%\nEpoch 0, Step 4000 - Training Loss: 0.101115783031928, Training Accuracy: 96.209375%\nEpoch 0 Completed - Average Loss: 0.10070144175213583, Average Accuracy: 96.22507342711393%, Time: 6331.07 seconds\nValidation Loss per 100 steps: tensor([0.0366, 0.0312], device='cuda:0')\nValidation Accuracy per 100 steps: 98.39108910891089\nValidation Loss per 100 steps: tensor([0.0461, 0.0510], device='cuda:0')\nValidation Accuracy per 100 steps: 98.19651741293532\nValidation Loss per 100 steps: tensor([0.0475, 0.0518], device='cuda:0')\nValidation Accuracy per 100 steps: 98.08970099667773\nValidation Loss per 100 steps: tensor([0.0569, 0.0584], device='cuda:0')\nValidation Accuracy per 100 steps: 97.81795511221945\nValidation Loss per 100 steps: tensor([0.0636, 0.0607], device='cuda:0')\nValidation Accuracy per 100 steps: 97.55489021956087\nValidation Loss per 100 steps: tensor([0.0609, 0.0666], device='cuda:0')\nValidation Accuracy per 100 steps: 97.50415973377704\nValidation Loss per 100 steps: tensor([0.0580, 0.0654], device='cuda:0')\nValidation Accuracy per 100 steps: 97.57489300998573\nValidation Loss per 100 steps: tensor([0.0539, 0.0620], device='cuda:0')\nValidation Accuracy per 100 steps: 97.75280898876404\nValidation Loss per 100 steps: tensor([0.0536, 0.0611], device='cuda:0')\nValidation Accuracy per 100 steps: 97.76637069922309\nValidation Loss per 100 steps: tensor([0.0557, 0.0643], device='cuda:0')\nValidation Accuracy per 100 steps: 97.68981018981019\nValidation Loss Epoch: tensor([0.0558, 0.0642], device='cuda:0')\nValidation Accuracy Epoch: 97.68764684060838\nAccuracy on validation data for epoch 0 = 97.69%\nEpoch 1, Step 100 - Training Loss: 0.03138094317575451, Training Accuracy: 98.875%\nEpoch 1, Step 200 - Training Loss: 0.03461248863051878, Training Accuracy: 98.875%\nEpoch 1, Step 300 - Training Loss: 0.0350827777152881, Training Accuracy: 98.875%\nEpoch 1, Step 400 - Training Loss: 0.03187419977824902, Training Accuracy: 98.96875%\nEpoch 1, Step 500 - Training Loss: 0.031366360688698476, Training Accuracy: 98.975%\nEpoch 1, Step 600 - Training Loss: 0.0332183332995434, Training Accuracy: 98.91666666666667%\nEpoch 1, Step 700 - Training Loss: 0.03364418125229089, Training Accuracy: 98.85714285714286%\nEpoch 1, Step 800 - Training Loss: 0.03775499824947474, Training Accuracy: 98.625%\nEpoch 1, Step 900 - Training Loss: 0.03662794542618536, Training Accuracy: 98.66666666666667%\nEpoch 1, Step 1000 - Training Loss: 0.03801688278527581, Training Accuracy: 98.6375%\nEpoch 1, Step 1100 - Training Loss: 0.03756386391167656, Training Accuracy: 98.63636363636364%\nEpoch 1, Step 1200 - Training Loss: 0.039824686951251353, Training Accuracy: 98.58333333333333%\nEpoch 1, Step 1300 - Training Loss: 0.04088424154774447, Training Accuracy: 98.53846153846153%\nEpoch 1, Step 1400 - Training Loss: 0.04132598961219108, Training Accuracy: 98.54464285714286%\nEpoch 1, Step 1500 - Training Loss: 0.0415534187645535, Training Accuracy: 98.54166666666667%\nEpoch 1, Step 1600 - Training Loss: 0.04097583196808045, Training Accuracy: 98.5703125%\nEpoch 1, Step 1700 - Training Loss: 0.04021564470578382, Training Accuracy: 98.6029411764706%\nEpoch 1, Step 1800 - Training Loss: 0.040886776898357007, Training Accuracy: 98.58333333333333%\nEpoch 1, Step 1900 - Training Loss: 0.04154243277951058, Training Accuracy: 98.52631578947368%\nEpoch 1, Step 2000 - Training Loss: 0.04223816854723555, Training Accuracy: 98.5%\nEpoch 1, Step 2100 - Training Loss: 0.04121559068399836, Training Accuracy: 98.53571428571429%\nEpoch 1, Step 2200 - Training Loss: 0.041456407869554825, Training Accuracy: 98.53977272727273%\nEpoch 1, Step 2300 - Training Loss: 0.04165473790784903, Training Accuracy: 98.54891304347827%\nEpoch 1, Step 2400 - Training Loss: 0.04196533699247084, Training Accuracy: 98.546875%\nEpoch 1, Step 2500 - Training Loss: 0.041506388207071, Training Accuracy: 98.57%\nEpoch 1, Step 2600 - Training Loss: 0.04081896111443012, Training Accuracy: 98.59615384615384%\nEpoch 1, Step 2700 - Training Loss: 0.04095422920065984, Training Accuracy: 98.57870370370371%\nEpoch 1, Step 2800 - Training Loss: 0.04089978282363778, Training Accuracy: 98.55357142857143%\nEpoch 1, Step 2900 - Training Loss: 0.04145894469045994, Training Accuracy: 98.53879310344827%\nEpoch 1, Step 3000 - Training Loss: 0.040605576761406456, Training Accuracy: 98.56666666666666%\nEpoch 1, Step 3100 - Training Loss: 0.040787968371662445, Training Accuracy: 98.55645161290323%\nEpoch 1, Step 3200 - Training Loss: 0.041149527070156185, Training Accuracy: 98.55078125%\nEpoch 1, Step 3300 - Training Loss: 0.040941927580879015, Training Accuracy: 98.5530303030303%\nEpoch 1, Step 3400 - Training Loss: 0.04051563258301244, Training Accuracy: 98.57352941176471%\nEpoch 1, Step 3500 - Training Loss: 0.04076228199306726, Training Accuracy: 98.56071428571428%\nEpoch 1, Step 3600 - Training Loss: 0.04058887794720148, Training Accuracy: 98.55208333333333%\nEpoch 1, Step 3700 - Training Loss: 0.04078561838644296, Training Accuracy: 98.55067567567568%\nEpoch 1, Step 3800 - Training Loss: 0.04034116509222689, Training Accuracy: 98.57236842105263%\nEpoch 1, Step 3900 - Training Loss: 0.04009029619250214, Training Accuracy: 98.58653846153847%\nEpoch 1, Step 4000 - Training Loss: 0.039507795498524505, Training Accuracy: 98.6125%\nEpoch 1 Completed - Average Loss: 0.03941657875998204, Average Accuracy: 98.6211160921317%, Time: 6317.55 seconds\nValidation Loss per 100 steps: tensor([0.0489, 0.1256], device='cuda:0')\nValidation Accuracy per 100 steps: 97.64851485148515\nValidation Loss per 100 steps: tensor([0.0729, 0.0755], device='cuda:0')\nValidation Accuracy per 100 steps: 97.82338308457712\nValidation Loss per 100 steps: tensor([0.0693, 0.0654], device='cuda:0')\nValidation Accuracy per 100 steps: 97.84053156146179\nValidation Loss per 100 steps: tensor([0.0652, 0.0546], device='cuda:0')\nValidation Accuracy per 100 steps: 98.09850374064838\nValidation Loss per 100 steps: tensor([0.0590, 0.0474], device='cuda:0')\nValidation Accuracy per 100 steps: 98.25349301397206\nValidation Loss per 100 steps: tensor([0.0539, 0.0456], device='cuda:0')\nValidation Accuracy per 100 steps: 98.35690515806988\nValidation Loss per 100 steps: tensor([0.0532, 0.0458], device='cuda:0')\nValidation Accuracy per 100 steps: 98.32382310984308\nValidation Loss per 100 steps: tensor([0.0541, 0.0446], device='cuda:0')\nValidation Accuracy per 100 steps: 98.31460674157303\nValidation Loss per 100 steps: tensor([0.0508, 0.0412], device='cuda:0')\nValidation Accuracy per 100 steps: 98.4322974472808\nValidation Loss per 100 steps: tensor([0.0483, 0.0428], device='cuda:0')\nValidation Accuracy per 100 steps: 98.43906093906094\nValidation Loss Epoch: tensor([0.0481, 0.0431], device='cuda:0')\nValidation Accuracy Epoch: 98.41721281068381\nAccuracy on validation data for epoch 1 = 98.42%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model\noutput_model_file = '/kaggle/working/ft-large-electra-amazonreviews.pt'\n\nmodel_to_save = model\ntorch.save(model_to_save, output_model_file)\n\nprint('All files saved')","metadata":{"_uuid":"8ed3bac3-4fc0-4425-8b43-a662ecd12c49","_cell_guid":"8cefc64f-fc0a-4b24-aa6b-18fcf0e90464","collapsed":false,"id":"l2B_50_WHqwa","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:45:05.166447Z","iopub.execute_input":"2023-12-16T20:45:05.166952Z","iopub.status.idle":"2023-12-16T20:45:06.920903Z","shell.execute_reply.started":"2023-12-16T20:45:05.166927Z","shell.execute_reply":"2023-12-16T20:45:06.919942Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"All files saved\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Inference","metadata":{"_uuid":"7245803f-d7fe-4f72-95fa-ac88a7a420ed","_cell_guid":"d12375a5-5943-4554-a84d-ba0f3e85189c","id":"ARivpmTiHqwa","trusted":true}},{"cell_type":"code","source":"model = torch.load('/kaggle/working/ft-large-electra-amazonreviews.pt')","metadata":{"_uuid":"71c86541-f3fc-4501-a3bb-2e8367761ab6","_cell_guid":"3932baf9-2c1e-4023-8337-b4c4e9abcdc0","collapsed":false,"id":"GXosfVtmHqwa","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:45:06.922130Z","iopub.execute_input":"2023-12-16T20:45:06.922520Z","iopub.status.idle":"2023-12-16T20:45:07.835087Z","shell.execute_reply.started":"2023-12-16T20:45:06.922485Z","shell.execute_reply":"2023-12-16T20:45:07.833967Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"device=\"cuda\"\nquery = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\ntokens = tokenizer.encode(query,return_tensors=\"pt\")\nall_tokens = len(tokens)\nmask = torch.ones_like(tokens)\n\nwith torch.no_grad():\n    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n    probs = logits.softmax(dim=-1)\n\nfake, real = probs.detach().cpu().flatten().numpy().tolist()\n\nprint(f\"Real Probability: {real}\\nFake Probability: {fake}\")","metadata":{"_uuid":"9523c659-68d8-4c91-a50d-f4c438aa0d1c","_cell_guid":"360aee62-e92c-4c08-b877-e68a731c5313","collapsed":false,"id":"Rzgiw2WyHqwa","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:45:07.836632Z","iopub.execute_input":"2023-12-16T20:45:07.836935Z","iopub.status.idle":"2023-12-16T20:45:08.006842Z","shell.execute_reply.started":"2023-12-16T20:45:07.836909Z","shell.execute_reply":"2023-12-16T20:45:08.005450Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Real Probability: 0.9998668432235718\nFake Probability: 0.0001331287348875776\n","output_type":"stream"}]},{"cell_type":"code","source":"device=\"cuda\"\nquery = \"\"\"My old bet was wearing this to the Macy's in January.  This is the first one I've ever had.  I am a 32D, and the first pair I bought were just a little tight.  I'm a bit disappointed.  This is my second pair.  I'm looking forward to wearing them to the Macy's in the fall.  I like the way they look.Love these!These are my favorite.  I have a hard time finding jeans that fit me comfortably, but I have a hard time finding jeans that don't fit.  These jeans are super comfortable and have a great price point.  I have some great jeans to wear for work, but these are the only jeans that I wear for work or for my family.  I will be buying more!  I have a lot of compliments on them.I love these shoes. I love the color and the fit. They fit my body well and are comfortable. I have a wide foot and these fit me well.\n\nI'm 5'4\", 130lbs and these fit well. I would recommend them.I wear a size 11.5 in jeans and this fits perfect. I have a narrow foot and this fits perfect. It is very comfortable and fits great. I bought a small and it fit perfectly. I will order another size up.I bought these for my husband, he loves them and he loves them!This is the best pair of sunglasses for the price!  They are so comfortable and easy to use.  I wear them all the time and they don't hurt my feet.  I wear them everyday and my feet are so happy with them!\"\"\"\ntokens = tokenizer.encode(query,return_tensors=\"pt\")\nall_tokens = len(tokens[0])\nmask = torch.ones_like(tokens)\n\nwith torch.no_grad():\n    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n    probs = logits.softmax(dim=-1)\n\nfake, real = probs.detach().cpu().flatten().numpy().tolist()\n\nprint(f\"Real Probability: {real}\\nFake Probability: {fake}\")","metadata":{"_uuid":"284f3824-d0c4-46ec-bd9a-7890d426c2bb","_cell_guid":"1dfbf4c0-2f3a-434c-b9c2-4b35e0d80b42","collapsed":false,"id":"lO1BJCCkHqwa","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:45:08.008275Z","iopub.execute_input":"2023-12-16T20:45:08.008640Z","iopub.status.idle":"2023-12-16T20:45:08.149503Z","shell.execute_reply.started":"2023-12-16T20:45:08.008606Z","shell.execute_reply":"2023-12-16T20:45:08.148675Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Real Probability: 9.206630056723952e-05\nFake Probability: 0.9999079704284668\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tokenizer.bos_token_id)\nprint(tokenizer.eos_token_id)","metadata":{"_uuid":"49b1d145-7736-4d46-81d2-62215a6a4014","_cell_guid":"55e31626-4498-45e9-a6eb-f57551250690","collapsed":false,"id":"EEfLblF--a6s","scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:45:08.150432Z","iopub.execute_input":"2023-12-16T20:45:08.150695Z","iopub.status.idle":"2023-12-16T20:45:08.155590Z","shell.execute_reply.started":"2023-12-16T20:45:08.150671Z","shell.execute_reply":"2023-12-16T20:45:08.154700Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"30522\n30523\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef predict_long_text(query, model, tokenizer, max_length=512, device=\"cuda\"):\n    # Tokenize the input text\n    tokens = tokenizer.encode(query, add_special_tokens=True)\n\n    # Split the tokens into segments\n    segments = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]\n\n    # Initialize variables to store results\n    fake_sum, real_sum = 0.0, 0.0\n\n    with torch.no_grad():\n        for segment in segments:\n            tokens_tensor = torch.tensor([segment]).to(device)\n            mask = torch.ones_like(tokens_tensor)\n\n            # Get model predictions for the segment\n            logits = model(tokens_tensor, attention_mask=mask)[0]\n            probs = logits.softmax(dim=-1)\n\n            fake, real = probs.detach().cpu().numpy()[:, 0], probs.detach().cpu().numpy()[:, 1]\n            fake_sum += sum(fake)\n            real_sum += sum(real)\n\n    return real_sum","metadata":{"_uuid":"ddc64617-19b5-46de-aa4d-6e217177b217","_cell_guid":"5f735613-bb82-4361-b72d-c0e5ba8cf572","collapsed":false,"id":"hCygsYPz-a6s","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:45:08.157053Z","iopub.execute_input":"2023-12-16T20:45:08.157326Z","iopub.status.idle":"2023-12-16T20:45:08.165438Z","shell.execute_reply.started":"2023-12-16T20:45:08.157302Z","shell.execute_reply":"2023-12-16T20:45:08.164706Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Usage\nquery = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\nresult = predict_long_text(query, model, tokenizer)\nprint(result)","metadata":{"_uuid":"b3e806da-d36a-4d49-954e-00f4a064bba2","_cell_guid":"5ba155de-0917-4e72-83b2-132a1410d205","collapsed":false,"id":"2eOiDrTh-a6s","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:45:08.166476Z","iopub.execute_input":"2023-12-16T20:45:08.166739Z","iopub.status.idle":"2023-12-16T20:45:08.302058Z","shell.execute_reply.started":"2023-12-16T20:45:08.166716Z","shell.execute_reply":"2023-12-16T20:45:08.300947Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0.9998668432235718\n","output_type":"stream"}]},{"cell_type":"code","source":"preds, preds_probas = [],[]\nfor i, row in valid_dataset.iterrows():\n    query = row[\"text_\"]\n    pred = predict_long_text(query,model,tokenizer)\n    preds_probas.append(pred)\n    if pred >= 0.5:\n        preds.append(1)\n    else:\n        preds.append(0)","metadata":{"_uuid":"ad1ea48a-2dae-4633-ac5a-78370856df51","_cell_guid":"3f7cbecb-854d-495f-a589-6e45bfdef0cd","collapsed":false,"id":"BjEHX33q-a6s","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:45:08.303356Z","iopub.execute_input":"2023-12-16T20:45:08.303781Z","iopub.status.idle":"2023-12-16T20:52:23.937869Z","shell.execute_reply.started":"2023-12-16T20:45:08.303746Z","shell.execute_reply":"2023-12-16T20:52:23.936844Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_true = valid_dataset.target.values\ny_pred = preds\nconfusion_matrix(y_true,y_pred)","metadata":{"_uuid":"901759a3-cc39-4d69-bb11-b4d3e6fd6c44","_cell_guid":"9535e22f-8fbb-4cd5-b086-938993bf68f3","collapsed":false,"id":"TeOl3me_Hqwc","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:52:23.939084Z","iopub.execute_input":"2023-12-16T20:52:23.939485Z","iopub.status.idle":"2023-12-16T20:52:23.952894Z","shell.execute_reply.started":"2023-12-16T20:52:23.939457Z","shell.execute_reply":"2023-12-16T20:52:23.951889Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"array([[3973,   37],\n       [  91, 3986]])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\nacc = accuracy_score(y_true,y_pred)\nprecision = precision_score(y_true,y_pred)\nrecall = recall_score(y_true,y_pred)","metadata":{"_uuid":"ee31a07a-63fa-414c-b7f8-9d6095ac2e69","_cell_guid":"23176965-2db0-4e66-ba3a-18bc84942aca","collapsed":false,"id":"uTgtUME1Hqwc","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:52:23.954150Z","iopub.execute_input":"2023-12-16T20:52:23.954441Z","iopub.status.idle":"2023-12-16T20:52:23.983431Z","shell.execute_reply.started":"2023-12-16T20:52:23.954417Z","shell.execute_reply":"2023-12-16T20:52:23.982709Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(f\"Accuracy: {acc*100}; Precision:{precision*100}; Recall:{recall*100}\")","metadata":{"_uuid":"71431ab8-290a-4593-ac8f-3afec6f1141b","_cell_guid":"47cbecf7-2bac-464b-a062-3da7fa35990f","collapsed":false,"id":"FcZ0qT1xHqwc","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:52:23.984532Z","iopub.execute_input":"2023-12-16T20:52:23.984879Z","iopub.status.idle":"2023-12-16T20:52:23.989793Z","shell.execute_reply.started":"2023-12-16T20:52:23.984846Z","shell.execute_reply":"2023-12-16T20:52:23.988915Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Accuracy: 98.41721281068382; Precision:99.08028834203331; Recall:97.76796664213883\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_true, y_pred, target_names=[\"CG\",\"OR\"]))","metadata":{"_uuid":"5fabdbef-4abb-4d2c-b0bc-f81dbfbd1ec6","_cell_guid":"985495b1-dacf-468b-8cf2-3cff3666e41d","collapsed":false,"id":"enlwXs3IHqwc","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:52:23.991023Z","iopub.execute_input":"2023-12-16T20:52:23.991528Z","iopub.status.idle":"2023-12-16T20:52:24.021591Z","shell.execute_reply.started":"2023-12-16T20:52:23.991494Z","shell.execute_reply":"2023-12-16T20:52:24.020778Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n          CG       0.98      0.99      0.98      4010\n          OR       0.99      0.98      0.98      4077\n\n    accuracy                           0.98      8087\n   macro avg       0.98      0.98      0.98      8087\nweighted avg       0.98      0.98      0.98      8087\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Writing predictions to disc","metadata":{"_uuid":"8afb54c1-bc25-495a-877d-8823548df6de","_cell_guid":"1488afe8-1dbd-46ba-a6d4-e3a93d6ede16","id":"8f3GnHe6Hqwc","trusted":true}},{"cell_type":"code","source":"preds_df_rows = []\nfor i, row in valid_dataset.iterrows():\n    query = row[\"text_\"]\n    pred_prob = preds_probas[i]\n    pred_label = preds[i]\n    preds_df_rows.append([pred_prob,pred_label])\npreds_df = pd.DataFrame(preds_df_rows, columns=[\"ELECTRA_Model_Probability\",\"ELECTRA_Model_Prediction\"])","metadata":{"_uuid":"3ec74fdb-4181-4b07-ba72-736a97856994","_cell_guid":"9c65c644-9c6d-4322-98cf-901cd12fdae7","collapsed":false,"id":"bfsIF4dQHqwc","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:52:24.022598Z","iopub.execute_input":"2023-12-16T20:52:24.022860Z","iopub.status.idle":"2023-12-16T20:52:24.502610Z","shell.execute_reply.started":"2023-12-16T20:52:24.022837Z","shell.execute_reply":"2023-12-16T20:52:24.501695Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"preds_df.to_csv(\"/kaggle/working/ft_largeELECTRA_predictions.csv\", index=None)","metadata":{"_uuid":"29f888f6-c6fb-40f8-a944-3820c8dc2a7e","_cell_guid":"e15b6461-a125-4cd2-a72e-e3bf77b78c24","collapsed":false,"id":"j_kX464zHqwc","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-16T20:52:24.503628Z","iopub.execute_input":"2023-12-16T20:52:24.503903Z","iopub.status.idle":"2023-12-16T20:52:24.539886Z","shell.execute_reply.started":"2023-12-16T20:52:24.503878Z","shell.execute_reply":"2023-12-16T20:52:24.539229Z"},"trusted":true},"execution_count":31,"outputs":[]}]}